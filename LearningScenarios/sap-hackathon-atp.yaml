apiVersion: argoproj.io/v1alpha1
kind: WorkflowTemplate
metadata:
  name: sap-hackathon-atp-pipeline # executable id, must be unique across all your workflows (YAML files)
  annotations:
    scenarios.ai.sap.com/description: "Ingest Data for sap-hackathon-atp"
    scenarios.ai.sap.com/name: "SAP Hackathon ATP Training (Recommendations)" # Scenario name should be the use case
    executables.ai.sap.com/description: "Train with legacy data"
    executables.ai.sap.com/name: "sap-hackathon-atp-executable" # Executable name should describe the workflow in the use case
    artifacts.ai.sap.com/sap-hackathon-atp-dataset.kind: "dataset" # Helps in suggesting the kind of inputs that can be attached.
    artifacts.ai.sap.com/sap_hackathon_atp_datamodel.kind: "model" # Helps in suggesting the kind of artifact that can be generated.
  labels:
    scenarios.ai.sap.com/id: "sap-hackathon-atp"
    ai.sap.com/version: "1.0"
spec:
  imagePullSecrets:
    - name: docker-rajatfjain216 # your docker registry secret
  entrypoint: sap-hackathon-atp-pipeline
  arguments:
    parameters: # placeholder for string like inputs
        - name: DT_MAX_DEPTH # identifier local to this workflow
  templates:
  - name: sap-hackathon-atp-pipeline
    steps:
    - - name: sap-hackathon-atp-predictor
        template: sap-hackathon-atp-codeblock1
  - name: sap-hackathon-atp-codeblock1
    inputs:
      artifacts:  # placeholder for cloud storage attachements
        - name: sap-hackathon-atp-dataset # a name for the placeholder
          path: /app/data/ # where to copy in the Dataset in the Docker image
    outputs:
      artifacts:
        - name: sap_hackathon_atp_datamodel # local identifier name to the workflow
          globalName: sap-hackathon-atp-model # name of the artifact generated, and folder name when placed in S3, complete directory will be `../<executaion_id>/housemodel`. Also used above in annotation
          path: /app/model/ # from which folder in docker image (after running workflow step) copy contents to cloud storage
          archive:
            none:   # specify not to compress while uploading to cloud
              {}
    container:
      image: docker.io/rajatfjain216/sap-hackathon-atp:01 # Your docker image name
      command: ["/bin/sh", "-c"]
      env:
        - name: DT_MAX_DEPTH # name of the environment variable inside Docker container
          value: "{{workflow.parameters.DT_MAX_DEPTH}}" # will make it as variable later
      args:
        - "python /app/src/main.py"
